{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Wichtig: \n",
    "\n",
    "in der Vorlesung besprochen!  \n",
    "\n",
    "* Diese Aufgabe wird als Team Projekt bewertet. (max. 3 Teilnehmer) \n",
    "* Die hier erreichten Punkte gehen zu 20% in Klausur-Bewertung ein.\n",
    "\n",
    "## Teilnehmer\n",
    "\n",
    "* Geben Sie hier im Dokument die Namen der Teilnehmer an! \n",
    "\n",
    "Teilnehmer: \n",
    "* Sebastian Trauth\n",
    "* Henrik Kaltenbach\n",
    "* Marlene Hill\n",
    "\n",
    "### Abgabe\n",
    "\n",
    "* Die Abgabe erfolgt über Moodle\n",
    "\n",
    "* Abzugeben ist ein jupyter Notebook mit\n",
    "    * Text, der beschreibt was und wieso sie die einzelnen Analyse-Schritte durchführen \n",
    "    * Pythoncode, der die einzelnen Schritte durchführt\n",
    "    * eine Zusammenfassung am Ende\n",
    "\n",
    "\n",
    "\n",
    "* Sie können neue Zellen mit Hilfe der Jupyter-Icons hinzufügen\n",
    "    * Sie können zwischen Markdown oder Code wählen \n",
    "\n",
    "* Export des Jupyter Notebooks\n",
    "    * save as --> ipynb\n",
    "\n",
    "* Das Jupyter Notebook zur Deadline in Moodle hochladen! \n",
    "    * der Name des JupyterNotebooks enthält auch die Namen der Teilnehmer\n",
    "\n",
    "### Kriterien\n",
    "\n",
    "* Sind die einzelnen Schritte gut dokumentiert und begründet? \n",
    "\n",
    "* Sind die bekannten in der Vorlesung vorgestellten Verfahren sinnvoll eingesetzt worden? \n",
    "    * Wurde begründet wieso ein Verfahren nicht weiter verfolgt wurde? \n",
    "\n",
    "* Wurde eine gute Klassifizierung erreicht? \n",
    "\n",
    "\n",
    "# Aufgabe zur Klassifizierung\n",
    "\n",
    "Im Verzeichnis data-classification finden Sie Daten aus einem MicroCensus\n",
    "* die Datei adult.data enthält Datenobjekte (zum Testen)\n",
    "* die Datei adult.test enthält Datenobjekte (zum Testen)\n",
    "* die Datei adult.names enthält Beschreibungen zu den Daten\n",
    "\n",
    "## Aufgaben \n",
    "\n",
    "Entwickeln Sie ein Klassifizierungsmodell, dass so genau wie möglich vorhersagt, ob eine Person ein Einkommen von mehr als 50000 Doller pro Jahr hat! \n",
    "* Verwenden Sie was sie bisher gelernt haben! \n",
    "* Seien Sie kritisch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ToDo\n",
    "\n",
    "* Datei umbenennen bei Abgabe\n",
    "* Alle müssen Datei abgeben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einlesen der Daten in eine Objekt-Liste\n",
    "\n",
    "Es werden die Trainings- und die Testdaten in Objektlisten eingelesen. Ein klar definierter Seperator sorgt für das korrekte Parsen. Die erste Zeile in `adult.test` enthält keinen Daten, sie kann also direkt entfernt werden.\n",
    "Die Trainingsdaten verfügen über 32561 Einträge, die Testdaten über 16281. Beide Datensätze bestehen aus 15 Merkmalen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "attributes": {
     "classes": [
      "python "
     ],
     "id": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: (32561, 15)\n",
      "Test data: (16282, 15)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('./data-classification/adult.data', sep=', ', engine='python', header=None, names=[\n",
    "'age', 'workclass', 'fnlwgt', \n",
    "'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', \n",
    "'sex' , 'capital-gain' , 'capital-loss',\n",
    "'hours-per-week', 'native-country', \"<50k\"\n",
    "])\n",
    "\n",
    "df_test = pd.read_csv('./data-classification/adult.test', sep=', ', engine='python', header=None, names=[\n",
    "'age', 'workclass', 'fnlwgt', \n",
    "'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', \n",
    "'sex' , 'capital-gain' , 'capital-loss',\n",
    "'hours-per-week', 'native-country', \"<50k\"\n",
    "])\n",
    "df_test.drop(index=0, inplace=True)\n",
    "\n",
    "print(\"Train data: \" + str(df_train.shape))\n",
    "print(\"Test data: \" + str(df_test.shape))\n",
    "\n",
    "#df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisieren der Daten\n",
    "\n",
    "1. Zwischen \"nominalen\" (ohne innere Ordnung) und \"ordinalen\" (mit natürlicher Ordnung) Kategorien unterscheiden.\n",
    "nominal: Blau, Rot, Grün\n",
    "         Mann, Frau\n",
    "         Bananen, Äpfel\n",
    "         \n",
    "ordinal: niedrig, mittel, hoch\n",
    "         jung, alt\n",
    "         \n",
    "2. Es werden numerische Werte als Eingabe vorausgesetzt.\n",
    "k-nächste-Nachbarn-Algorithmus berechnet Abstände zwischen Beobachtungen (oftmals euklidischer Abstand)\n",
    "\n",
    "$\\sqrt{\\sum\\nolimits_{n=1}^N (x_i - y_i)^2}$ \n",
    "\n",
    "3. String muss in numerisches Format gebracht werden\n",
    "\n",
    "nominal: \n",
    "scikit-Bibliothek \"LabelBinarizer -> One-Hot-Codierung\n",
    "\n",
    "Pandas lässt sich auch auf die Transformierte anwenden\n",
    "\n",
    "ordinal kategorisch: \n",
    "DataFrame-Methode \"replace\" von pandas um String-Bezeichner in numerische Äquivalente zu transformieren\n",
    "\n",
    "4. Fehlende Klassenwerte imputieren\n",
    "\n",
    "In einem kategorisches Merkmal fehlende Werte (unser \"?\") ersetzten durch vorhergesagte Werte.\n",
    "\n",
    "Trainieren eines k-nächste-Nachbarn-(KNN)-Klassifikators um fehlende Werte vorherzusagen.\n",
    "\n",
    "\n",
    "Idee: Grouped bar chart jeweils für <=50K und für >50K\n",
    "\n",
    "Balkengruppe=Kriterium, so viele Balken wie mögliche Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.plot()\n",
    "#df_test.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vorbereitung der Daten\n",
    "\n",
    "Die Daten sind nicht direkt so nutzbar.\n",
    "Sie enthalten einige Fehler die entfernt werden müssen.\n",
    "Außerdem können die Merkmale in dem Format in dem sie vorliegen nicht verarbeitet werden und müssen verändert werden.\n",
    "Diese Schritte werden hier beschrieben und umgesetzt.\n",
    "Diese Schritte müssen auf die Test- wie auch auf die Trainingsdaten angewendet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Fehlerhaften Daten**\n",
    "\n",
    "In den beiden Datensätzen sind ungültige Werte wie \"?\" oder fehlende Daten vorhanden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Unterschiedlichen Datentypen**\n",
    "\n",
    "Int/Double, Strings, (Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Formatierung und Satzzeichen**\n",
    "\n",
    "unterschiedliche Formatierung, Satzzeichen, Whitespaces, ...\n",
    "\n",
    "Strings bereinigen --> strip, replace, split\n",
    "\n",
    "Whitepaces entfernen etc., Satzzeichen, \"-\"\n",
    "\n",
    "Soll Text in Tokens zerlegt werden? Einzelne Wörter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4) Duplikate**\n",
    "\n",
    "Doppelte Einträge\n",
    "Redundante Spalten/Informationen\n",
    "\n",
    "Gibt es keine, siehe Code unten.\n",
    "\n",
    "TODO: Begründen, warum nach Duplikaten suchen wichtig ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1        False\n",
       "2        False\n",
       "3        False\n",
       "4        False\n",
       "5        False\n",
       "         ...  \n",
       "16277    False\n",
       "16278    False\n",
       "16279    False\n",
       "16280    False\n",
       "16281    False\n",
       "Length: 16281, dtype: bool"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Auf Duplikate untersuchen\n",
    "df_train.duplicated(keep=False)\n",
    "df_test.duplicated(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5) Ungenaue Daten**\n",
    "\n",
    "fnlwgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6) Merkmale auf numerische Werte mappen**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(dataFrame: pd.DataFrame):\n",
    "    #1 Ungültige Einträge entfernen\n",
    "    dataFrame.replace(to_replace='?', value=pd.NA, inplace=True)\n",
    "    dataFrame.replace(to_replace='None', value=pd.NA, inplace=True)\n",
    "    dataFrame.dropna(inplace=True)\n",
    "\n",
    "    #2 Unterschiedliche Datentypen\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufteilung der Daten\n",
    "\n",
    "In Ausgangsdaten und Zielwerte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisierung\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merkmalauswahl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unterschiedliche Datentypen\n",
    "\n",
    "String in numerische Werte umwandeln\n",
    "\n",
    "### Anpassung der Merkmale\n",
    "\n",
    "Standardisierung\n",
    "\n",
    "### Ausgewogene Klassen\n",
    "\n",
    "Wenn nicht, müssen die Metriken verändert werden mit denen die Klassen bewertet werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten komprimieren\n",
    "\n",
    "PCA, LDA, Kernel-PCA ALgorithmen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lernmethoden\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b89b5cfaba6639976dc87ff2fec6d58faec662063367e2c229c520fe71072417"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "rise": {
   "autolaunch": true,
   "footer": "<div style=\"padding-left: 300px; font-size:12px\" class='dhbwfooter'>Enterprise Data Science Center - DHBW Mannheim / &copy; Prof. Dr. Kornmayer</div>",
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
